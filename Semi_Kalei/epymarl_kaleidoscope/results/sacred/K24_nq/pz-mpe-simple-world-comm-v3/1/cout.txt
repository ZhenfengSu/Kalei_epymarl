[INFO 13:38:37] pymarl Running command 'my_main'
[INFO 13:38:37] pymarl Started run with ID "1"
[DEBUG 13:38:37] pymarl Starting Heartbeat
[DEBUG 13:38:37] my_main Started
[INFO 13:38:37] my_main Experiment Parameters:
[INFO 13:38:37] my_main 

{   'K24_args': {   'anneal_end': 0.8,
                    'anneal_end_step': 2400000,
                    'anneal_start': 0.4,
                    'deque_len': 100,
                    'div_coef': 0.1,
                    'ema_momentum': 0.9,
                    'hetero_init_scale': 0.01,
                    'kl_threshold': 0.1,
                    'prune_start_ratio': 0.4,
                    'reset_interval': 10000,
                    'reset_ratio': 0.1,
                    'sparse_gpt_steps': 100,
                    'temperature_init': 5.0,
                    'temperature_min': 0.2,
                    'use_adaptive_reset': False,
                    'use_sparse_gpt_first': True},
    'action_selector': 'epsilon_greedy',
    'add_value_last_step': True,
    'agent': 'k24_rnn_1R3',
    'agent_output_type': 'q',
    'batch_size': 64,
    'batch_size_run': 1,
    'buffer_cpu_only': True,
    'buffer_size': 5000,
    'checkpoint_path': '',
    'common_reward': True,
    'double_q': True,
    'env': 'gymma',
    'env_args': {   'key': 'pz-mpe-simple-world-comm-v3',
                    'pretrained_wrapper': None,
                    'seed': 0,
                    'time_limit': 25},
    'epsilon_anneal_time': 50000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': False,
    'evaluation_epsilon': 0.0,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'hidden_dim': 64,
    'hypergroup': None,
    'hypernet_embed': 64,
    'hypernet_layers': 2,
    'label': 'default_label',
    'learner': 'k24_q_learner',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 50000,
    'lr': 0.0005,
    'mac': 'kalei_mac',
    'mixer': 'qmix',
    'mixing_embed_dim': 32,
    'name': 'K24_nq',
    'obs_agent_id': True,
    'obs_last_action': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'optimizer': 'adam',
    'q_lambda': False,
    'render': False,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'runner': 'episode',
    'runner_log_interval': 10000,
    'save_model': False,
    'save_model_interval': 50000,
    'save_replay': False,
    'seed': 0,
    'standardise_returns': False,
    'standardise_rewards': True,
    't_max': 3050000,
    'target_update_interval': 200,
    'target_update_interval_or_tau': 200,
    'td_lambda': 0.6,
    'test_greedy': True,
    'test_interval': 50000,
    'test_nepisode': 100,
    'use_cuda': True,
    'use_rnn': True,
    'use_tensorboard': False,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

/root/anaconda3/envs/mpe/lib/python3.11/site-packages/pettingzoo/utils/conversions.py:158: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  warnings.warn(
/root/anaconda3/envs/mpe/lib/python3.11/site-packages/pettingzoo/utils/conversions.py:144: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  warnings.warn(
[INFO 13:38:37] my_main Beginning training for 3050000 timesteps
/root/anaconda3/envs/mpe/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:245: UserWarning: [33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'list'>[0m
  logger.warn(
[INFO 13:38:38] my_main t_env: 25 / 3050000
[INFO 13:38:38] my_main Estimated time left: 12 seconds. Time passed: 0 seconds
